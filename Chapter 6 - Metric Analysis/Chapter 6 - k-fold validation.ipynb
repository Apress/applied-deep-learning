{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Deep Learning - a use case based approach to understand deep neural networks\n",
    "\n",
    "### Umberto Michelucci\n",
    "\n",
    "Buy the book: https://www.apress.com/us/book/9781484237892"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(C) Umberto Michelucci 2018-2019 - umberto.michelucci@gmail.com \n",
    "\n",
    "github repository: https://github.com/Apress/applied-deep-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get MNIST data we use the function fetch_mldata, in the datasets package. Let's get all the dataset, and then we will select only the digits we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COL_NAMES': ['label', 'data'],\n",
       " 'DESCR': 'mldata.org dataset: mnist-original',\n",
       " 'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8),\n",
       " 'target': array([0., 0., 0., ..., 9., 9., 9.])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinput_,yinput_ = mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xinput_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yinput_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To know how many digits we have we can run this simple code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit 0 appear 6903 times\n",
      "digit 1 appear 7877 times\n",
      "digit 2 appear 6990 times\n",
      "digit 3 appear 7141 times\n",
      "digit 4 appear 6824 times\n",
      "digit 5 appear 6313 times\n",
      "digit 6 appear 6876 times\n",
      "digit 7 appear 7293 times\n",
      "digit 8 appear 6825 times\n",
      "digit 9 appear 6958 times\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(10):\n",
    "    print (\"digit\", i, \"appear\", np.count_nonzero(yinput_ == i), \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit 0 makes 9.9 % of the 70000 observations\n",
      "digit 1 makes 11.3 % of the 70000 observations\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(2):\n",
    "    print (\"digit\", i, \"makes\", np.around(np.count_nonzero(yinput_ == i)/70000.0*100.0, decimals=1), \"% of the 70000 observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-fold dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinput = Xinput_[np.any([yinput_ == 1,yinput_ == 2], axis = 0)]\n",
    "yinput = yinput_[np.any([yinput_ == 1,yinput_ == 2], axis = 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "yinput = yinput - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 makes 53.0 % of the 14867 observations\n",
      "Label 1 makes 47.0 % of the 14867 observations\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(0,2,1):\n",
    "    print (\"Label\", i, \"makes\", np.around(np.count_nonzero(yinput == i)/14867.0*100.0, decimals=1), \"% of the 14867 observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to remove 3 observations to make the division by 10 (for the folds) easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinput = Xinput[:-7,:]\n",
    "yinput = yinput[:-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14860"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Xinput.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8a9c62518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit = Xinput[8999,:]\n",
    "\n",
    "some_digit_image = some_digit.reshape(28,28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation = \"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of folds: 10\n",
      "Number of elements in each fold: 1486\n"
     ]
    }
   ],
   "source": [
    "foldnumber = 10\n",
    "idx = np.arange(0,Xinput.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "al = np.array_split(idx,foldnumber)\n",
    "\n",
    "print('Number of folds:',len(al))\n",
    "print('Number of elements in each fold:',len(al[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinputfold = []\n",
    "yinputfold = []\n",
    "for i in range(foldnumber):\n",
    "    tmp = Xinput[al[i],:]\n",
    "    Xinputfold.append(tmp)\n",
    "    ytmp = yinput[al[i]]\n",
    "    yinputfold.append(ytmp)\n",
    "\n",
    "    \n",
    "Xinputfold = np.asarray(Xinputfold)\n",
    "yinputfold = np.asarray(yinputfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1486, 784)\n",
      "(10, 1486)\n"
     ]
    }
   ],
   "source": [
    "print(Xinputfold.shape)\n",
    "print(yinputfold.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAABD9JREFUeJzt3bFKo1sUgNHrZaxUMIIvYKugYCkWCla+Y3pfxEo7K5tUgoi1WOntBzzXmZhE/NZqd/7kNB+7ODGuvb+//wP0/LvqAwCrIX6IEj9EiR+ixA9R4oco8UOU+CFK/BD1a8mf5+uEsHhrn3mRzQ9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iPq16gPwvc1ms+H89PR0OJ9MJh/Orq+vh89ubW0N58zH5oco8UOU+CFK/BAlfogSP0SJH6Lc8zP08PCwsPnLy8vwWff8i2XzQ5T4IUr8ECV+iBI/RIkfolz1sVC7u7sfztbX15d4En5n80OU+CFK/BAlfogSP0SJH6LED1Hu+Vmoy8vLD2c7OztLPAm/s/khSvwQJX6IEj9EiR+ixA9R4oco9/wMTafTVR+BBbH5IUr8ECV+iBI/RIkfosQPUeKHKPf8DD0/P6/6CCyIzQ9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iPInvXGPj4/D+d3d3Vzvf35+PtfzLI7ND1HihyjxQ5T4IUr8ECV+iBI/RLnnj7u/vx/OZ7PZcL61tTWcn5yc/PGZWA6bH6LED1HihyjxQ5T4IUr8ECV+iHLPHzedTud6/uzsbDjf29ub6/1ZHJsfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8EOWnu3+4p6en4fzq6mpJJ+G7sfkhSvwQJX6IEj9EiR+ixA9R4oco9/w/3Nvb23D++vq6pJPw3dj8ECV+iBI/RIkfosQPUeKHKPFDlHt+5nJxcbHqI/CXbH6IEj9EiR+ixA9R4oco8UOU+CHKPT9zOTo6WvUR+Es2P0SJH6LED1HihyjxQ5T4IcpVH0MHBwfD+f7+/pJOwlez+SFK/BAlfogSP0SJH6LED1Hihyj3/Axtb28P55PJZEkn4avZ/BAlfogSP0SJH6LED1HihyjxQ5R7foZubm6G89vb2+H8+Pj4K4/DF7L5IUr8ECV+iBI/RIkfosQPUeKHKPf8P9zGxsZw/n+/y7+5uTmcHx4e/vGZ+B5sfogSP0SJH6LED1HihyjxQ5T4IWrt/f19mZ+31A+DqLXPvMjmhyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHKPFDlPghSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0Qt+190f+onhYHFs/khSvwQJX6IEj9EiR+ixA9R4oco8UOU+CFK/BAlfogSP0SJH6LED1HihyjxQ5T4IUr8ECV+iBI/RIkfosQPUeKHqP8A08NETVK1qy0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8afc70908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit = Xinputfold[0][1234,:]\n",
    "\n",
    "some_digit_image = some_digit.reshape(28,28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation = \"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratio of ones and twos in Fold 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit 0 makes 53.4 % of the 1486 observations\n",
      "digit 1 makes 46.6 % of the 1486 observations\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(0,2,1):\n",
    "    print (\"digit\", i, \"makes\", np.around(np.count_nonzero(yinputfold[0] == i)/1486.0*100.0, decimals=1), \"% of the 1486 observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data normalization and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xinputfold_normalized = np.zeros_like(Xinputfold, dtype = float)\n",
    "for i in range (foldnumber):\n",
    "    Xinputfold_normalized[i] = Xinputfold[i]/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(foldnumber):\n",
    "    tmp = Xinputfold_normalized[i].transpose()\n",
    "    ytmp = yinputfold[i].reshape(1,yinputfold[i].shape[0])\n",
    "    X_train.append(tmp)\n",
    "    y_train.append(ytmp)\n",
    "    \n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 784, 1486)\n",
      "(10, 1, 1486)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8afd06198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_digit = X_train[0][:,10]\n",
    "\n",
    "some_digit_image = some_digit.reshape(28,28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap = matplotlib.cm.binary, interpolation = \"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [1, None])\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1, n_dim], stddev= 2.0 / np.sqrt(2.0*n_dim))) \n",
    "b = tf.Variable(tf.zeros(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = tf.sigmoid(tf.matmul(W,X)+b)\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "training_step = tf.train.AdamOptimizer(learning_rate = learning_rate, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8).minimize(cost)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_model(learning_r, training_epochs, train_obs, train_labels, debug = False):\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    \n",
    "    cost_history = np.empty(shape=[0], dtype = float)\n",
    "\n",
    "    for epoch in range(training_epochs+1):\n",
    "        \n",
    "        sess.run(training_step, feed_dict = {X: train_obs, Y: train_labels, learning_rate: learning_r})\n",
    "\n",
    "        cost_ = sess.run(cost, feed_dict={ X:train_obs, Y: train_labels, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "        \n",
    "        if (epoch % 200 == 0) & debug:\n",
    "            print(\"Reached epoch\",epoch,\"cost J =\", str.format('{0:.6f}', cost_))\n",
    "            \n",
    "    return sess, cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on Fold 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the shape of ```X_train[1]``` is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 1486)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train our network on Fold with index ```1```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.779379\n",
      "Reached epoch 200 cost J = 0.166642\n",
      "Reached epoch 400 cost J = 0.094669\n",
      "Reached epoch 600 cost J = 0.068902\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = run_logistic_model(learning_r = 5e-4, \n",
    "                                training_epochs = 600, \n",
    "                                train_obs = X_train[1], \n",
    "                                train_labels = y_train[1], \n",
    "                                debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9858681\n"
     ]
    }
   ],
   "source": [
    "correct_prediction=tf.equal(tf.greater(y_, 0.5), tf.equal(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Train accuracy:',sess.run(accuracy, feed_dict={X:X_train[1], Y: y_train[1], learning_rate: 0.01}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev fold is 0\n",
      "Reached epoch 0 cost J = 0.643606\n",
      "Reached epoch 200 cost J = 0.147986\n",
      "Reached epoch 400 cost J = 0.089260\n",
      "Reached epoch 600 cost J = 0.067967\n",
      "Train accuracy: 0.98691493\n",
      "Dev accuracy: 0.9899058\n",
      "Dev fold is 1\n",
      "Reached epoch 0 cost J = 0.702176\n",
      "Reached epoch 200 cost J = 0.160618\n",
      "Reached epoch 400 cost J = 0.096536\n",
      "Reached epoch 600 cost J = 0.073037\n",
      "Train accuracy: 0.9873635\n",
      "Dev accuracy: 0.9845222\n",
      "Dev fold is 2\n",
      "Reached epoch 0 cost J = 0.760782\n",
      "Reached epoch 200 cost J = 0.171399\n",
      "Reached epoch 400 cost J = 0.101488\n",
      "Reached epoch 600 cost J = 0.075848\n",
      "Train accuracy: 0.9867654\n",
      "Dev accuracy: 0.9858681\n",
      "Dev fold is 3\n",
      "Reached epoch 0 cost J = 0.721512\n",
      "Reached epoch 200 cost J = 0.161293\n",
      "Reached epoch 400 cost J = 0.096696\n",
      "Reached epoch 600 cost J = 0.073008\n",
      "Train accuracy: 0.9874383\n",
      "Dev accuracy: 0.9831763\n",
      "Dev fold is 4\n",
      "Reached epoch 0 cost J = 0.653751\n",
      "Reached epoch 200 cost J = 0.156322\n",
      "Reached epoch 400 cost J = 0.093289\n",
      "Reached epoch 600 cost J = 0.070187\n",
      "Train accuracy: 0.98721397\n",
      "Dev accuracy: 0.98519516\n",
      "Dev fold is 5\n",
      "Reached epoch 0 cost J = 0.597812\n",
      "Reached epoch 200 cost J = 0.146054\n",
      "Reached epoch 400 cost J = 0.090144\n",
      "Reached epoch 600 cost J = 0.069072\n",
      "Train accuracy: 0.98631674\n",
      "Dev accuracy: 0.9905787\n",
      "Dev fold is 6\n",
      "Reached epoch 0 cost J = 0.770245\n",
      "Reached epoch 200 cost J = 0.167554\n",
      "Reached epoch 400 cost J = 0.098435\n",
      "Reached epoch 600 cost J = 0.073224\n",
      "Train accuracy: 0.9873635\n",
      "Dev accuracy: 0.98721397\n",
      "Dev fold is 7\n",
      "Reached epoch 0 cost J = 0.723129\n",
      "Reached epoch 200 cost J = 0.166977\n",
      "Reached epoch 400 cost J = 0.099805\n",
      "Reached epoch 600 cost J = 0.075082\n",
      "Train accuracy: 0.98654103\n",
      "Dev accuracy: 0.9845222\n",
      "Dev fold is 8\n",
      "Reached epoch 0 cost J = 0.782519\n",
      "Reached epoch 200 cost J = 0.174685\n",
      "Reached epoch 400 cost J = 0.103458\n",
      "Reached epoch 600 cost J = 0.077259\n",
      "Train accuracy: 0.9860924\n",
      "Dev accuracy: 0.98654103\n",
      "Dev fold is 9\n",
      "Reached epoch 0 cost J = 0.775711\n",
      "Reached epoch 200 cost J = 0.173277\n",
      "Reached epoch 400 cost J = 0.102462\n",
      "Reached epoch 600 cost J = 0.076471\n",
      "Train accuracy: 0.98579335\n",
      "Dev accuracy: 0.9845222\n"
     ]
    }
   ],
   "source": [
    "train_acc = []\n",
    "dev_acc = []\n",
    "\n",
    "\n",
    "for i in range (foldnumber): \n",
    "    \n",
    "    # Prepare the folds\n",
    "    lis = []\n",
    "    ylis = []\n",
    "    for k in np.delete(np.arange(foldnumber), i):\n",
    "        lis.append(X_train[k])\n",
    "        ylis.append(y_train[k])\n",
    "        X_train_ = np.concatenate(lis, axis = 1)\n",
    "        y_train_ = np.concatenate(ylis, axis = 1)\n",
    "    X_train_ = np.asarray(X_train_)\n",
    "    y_train_ = np.asarray(y_train_)\n",
    "    \n",
    "    X_dev_ = X_train[i]\n",
    "    y_dev_ = y_train[i]\n",
    "    \n",
    "    print('Dev fold is', i)\n",
    "    sess, cost_history = run_logistic_model(learning_r = 5e-4, \n",
    "                                training_epochs = 600, \n",
    "                                train_obs = X_train_, \n",
    "                                train_labels = y_train_, \n",
    "                                debug = True)\n",
    "    \n",
    "    correct_prediction=tf.equal(tf.greater(y_, 0.5), tf.equal(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Train accuracy:',sess.run(accuracy, feed_dict={X:X_train_, Y: y_train_, learning_rate: 5e-4}))\n",
    "    train_acc = np.append( train_acc, sess.run(accuracy, feed_dict={X:X_train_, Y: y_train_, learning_rate: 5e-4}))\n",
    "\n",
    "    \n",
    "    correct_prediction=tf.equal(tf.greater(y_, 0.5), tf.equal(Y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print('Dev accuracy:',sess.run(accuracy, feed_dict={X:X_dev_, Y: y_dev_, learning_rate: 5e-4}))\n",
    "    dev_acc = np.append( dev_acc, sess.run(accuracy, feed_dict={X:X_dev_, Y: y_dev_, learning_rate: 5e-4}))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9874383211135864"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9905787110328674"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(dev_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train std-dev 0.0005512819947541776\n",
      "dev std-dev 0.0022969019517442746\n",
      "trian avg 0.9867803156375885\n",
      "dev avg 0.9862045705318451\n"
     ]
    }
   ],
   "source": [
    "train_std = np.std(train_acc)\n",
    "dev_std = np.std(dev_acc)\n",
    "\n",
    "train_avg = np.average(train_acc)\n",
    "dev_avg = np.average(dev_acc)\n",
    "\n",
    "print('train std-dev', train_std)\n",
    "print('dev std-dev',dev_std)\n",
    "\n",
    "print('trian avg',train_avg)\n",
    "print('dev avg',dev_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e8c18f9f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('font', family='arial')\n",
    "plt.rc('xtick', labelsize='x-small')\n",
    "plt.rc('ytick', labelsize='x-small')\n",
    "    \n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.hist(train_acc, bins = 5, color = 'black', alpha = 0.5)\n",
    "ax.set_ylim(0,6)\n",
    "ax.set_xlim(0.982,0.991)\n",
    "ax.set_xlabel('Train Accuracy', fontsize = 16)\n",
    "ax.set_ylabel('Count', fontsize = 16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.set_ylim(0,6)\n",
    "ax.set_xlim(0.982,0.991)\n",
    "plt.hist(dev_acc, bins = 5, color = 'black', alpha = 0.5)\n",
    "ax.set_xlabel('Dev Accuracy', fontsize = 16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case for splitting with 1-vs-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = np.zeros_like(yinput_)\n",
    "y_[np.any([yinput_ == 0], axis = 0)] = 0\n",
    "y_[np.any([yinput_ > 0], axis = 0)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xinput_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "rnd = np.random.rand(len(y_)) < 0.8\n",
    "\n",
    "X_train = Xinput_[rnd,:]\n",
    "y_train = y_[rnd]\n",
    "X_dev = Xinput_[~rnd,:]\n",
    "y_dev = y_[~rnd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 makes 9.9 % of the 56056 observations\n",
      "class 1 makes 90.1 % of the 56056 observations\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(2):\n",
    "    print (\"class\", i, \"makes\", np.around(np.count_nonzero(y_train == i)/56056.0*100.0, decimals=1), \"% of the 56056 observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 makes 9.7 % of the 13944 observations\n",
      "class 1 makes 90.3 % of the 13944 observations\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(2):\n",
    "    print (\"class\", i, \"makes\", np.around(np.count_nonzero(y_dev == i)/13944.0*100.0, decimals=1), \"% of the 13944 observations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 appears 5547  times\n",
      "class 1 appears 50509  times\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(2):\n",
    "    print (\"class\", i, \"appears\", np.count_nonzero(y_train == i), \" times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalise our data. The pixel will have a value between 0 and 255 (gray values). Let's normalise the value between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_normalised = X_train/255.0\n",
    "X_dev_normalised = X_dev/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we need features along the rows, and training cases along the columns. So let's reshape our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tr = X_train_normalised.transpose()\n",
    "y_train_tr = y_train.reshape(1,y_train.shape[0])\n",
    "\n",
    "X_dev_tr = X_dev_normalised.transpose()\n",
    "y_dev_tr = y_dev.reshape(1,y_dev.shape[0])\n",
    "\n",
    "\n",
    "n_dim = X_train_tr.shape[0]\n",
    "dim_train = X_train_tr.shape[1]\n",
    "dim_dev = X_dev_tr.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give our variables reasonable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = X_train_tr\n",
    "ytrain = y_train_tr\n",
    "\n",
    "Xdev = X_dev_tr\n",
    "ydev = y_dev_tr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 56056)\n",
      "(1, 56056)\n",
      "(784, 13944)\n",
      "(1, 13944)\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(Xdev.shape)\n",
    "print(ydev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [n_dim, None])\n",
    "Y = tf.placeholder(tf.float32, [1, None])\n",
    "learning_rate = tf.placeholder(tf.float32, shape=())\n",
    "\n",
    "W = tf.Variable(tf.zeros([1, n_dim]))\n",
    "b = tf.Variable(tf.zeros(1))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = tf.sigmoid(tf.matmul(W,X)+b)\n",
    "cost = - tf.reduce_mean(Y * tf.log(y_)+(1-Y) * tf.log(1-y_))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_model(learning_r, training_epochs, train_obs, train_labels, debug = False):\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    \n",
    "    cost_history = np.empty(shape=[0], dtype = float)\n",
    "\n",
    "    for epoch in range(training_epochs+1):\n",
    "        \n",
    "        sess.run(training_step, feed_dict = {X: train_obs, Y: train_labels, learning_rate: learning_r})\n",
    "\n",
    "        cost_ = sess.run(cost, feed_dict={ X:train_obs, Y: train_labels, learning_rate: learning_r})\n",
    "        cost_history = np.append(cost_history, cost_)\n",
    "        \n",
    "        if (epoch % 10 == 0) & debug:\n",
    "            print(\"Reached epoch\",epoch,\"cost J =\", str.format('{0:.6f}', cost_))\n",
    "            \n",
    "    return sess, cost_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached epoch 0 cost J = 0.639774\n",
      "Reached epoch 10 cost J = 0.412214\n",
      "Reached epoch 20 cost J = 0.349503\n",
      "Reached epoch 30 cost J = 0.317864\n",
      "Reached epoch 40 cost J = 0.295897\n",
      "Reached epoch 50 cost J = 0.278217\n",
      "Reached epoch 60 cost J = 0.263053\n",
      "Reached epoch 70 cost J = 0.249696\n",
      "Reached epoch 80 cost J = 0.237795\n",
      "Reached epoch 90 cost J = 0.227135\n",
      "Reached epoch 100 cost J = 0.217555\n"
     ]
    }
   ],
   "source": [
    "sess, cost_history = run_logistic_model(learning_r = 0.01, \n",
    "                                training_epochs = 100, \n",
    "                                train_obs = Xtrain, \n",
    "                                train_labels = ytrain, \n",
    "                                debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91269445\n"
     ]
    }
   ],
   "source": [
    "correct_prediction1=tf.equal(tf.greater(y_, 0.5), tf.equal(Y,1))\n",
    "accuracy1 = tf.reduce_mean(tf.cast(correct_prediction1, tf.float32))\n",
    "print(sess.run(accuracy1, feed_dict={X:Xtrain, Y: ytrain, learning_rate: 0.05}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  659,  4888],\n",
       "       [    6, 50503]], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = sess.run(tf.greater(y_, 0.5), feed_dict={X:Xtrain, Y: ytrain, learning_rate: 0.05}).flatten().astype(int)\n",
    "confusion_matrix(ytrain.flatten(), ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  150,  1206],\n",
       "       [    2, 12586]], dtype=int64)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred = sess.run(tf.greater(y_, 0.5), feed_dict={X:Xdev, Y: ydev, learning_rate: 0.05}).flatten().astype(int)\n",
    "confusion_matrix(ydev.flatten(), ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91336775\n"
     ]
    }
   ],
   "source": [
    "correct_prediction1=tf.equal(tf.greater(y_, 0.5), tf.equal(Y,1))\n",
    "accuracy1 = tf.reduce_mean(tf.cast(correct_prediction1, tf.float32))\n",
    "print(sess.run(accuracy1, feed_dict={X:Xdev, Y: ydev, learning_rate: 0.05}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: use downsampling to fit the data - difficulty: medium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new dataset taking balanced classes, meaning you need only 10% of class 1. Train your network with the new dataset and check the confusion matrix. What is different from the example above? What do you expect and do you get it?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
